{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "toc_visible": true,
      "authorship_tag": "ABX9TyMwbm/0Zy86ns3erQfaqmKc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wongdongwook/JSAC_MA-DeepSC/blob/main/CyclegAN_(DA)_for_4digits.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4-Digits CycleGAN: Data Domain Adaptation via CycleGAN  \n",
        "This Colab notebook implements domain adaptation experiments on 4 digits datasets‚Äî**MNIST, MNIST-M, SYN, USPS**‚Äîusing a CycleGAN-based approach.  \n",
        "\n",
        "The implementation is inspired by and aligns with the method described in:  \n",
        "üìÑ **Deep Learning-Enabled Semantic Communication Systems with Task-Unaware Transmitter and Dynamic Data**\n",
        "> [arXiv:2205.00271](https://arxiv.org/abs/2205.00271)\n",
        "\n",
        "### üîç Key Features:\n",
        "- **Unpaired image-to-image translation** between domains using CycleGAN.\n",
        "- **Domain combinations**: MNIST ‚Üî SYN, MNIST ‚Üî USPS, SYN ‚Üî USPS.\n",
        "- **Cycle-consistency loss** to preserve image semantics.\n",
        "- **PatchGAN Discriminator** for high-frequency detail preservation.\n",
        "- **Digit classification** model to evaluate semantic preservation after translation.\n",
        "\n",
        "This notebook is designed for adaptation studies in low-resource or visually distinct digit domains.\n"
      ],
      "metadata": {
        "id": "_Xc3i7ys7X5z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Configuration"
      ],
      "metadata": {
        "id": "w9O0O_h6m-mU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XXIirDYVm3aJ"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision.utils as vutils\n",
        "from torch import optim\n",
        "from torchvision.transforms.functional import to_pil_image\n",
        "from torchvision import datasets\n",
        "from torchvision import transforms\n",
        "import numpy as np\n",
        "import os\n",
        "import math\n",
        "from tqdm import tqdm\n",
        "import datetime\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "import pandas as pd\n",
        "from google.colab import drive"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# GPU Compatibility\n",
        "is_cuda = torch.cuda.is_available()\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print('Using ' + str(device).upper())\n",
        "drive.mount(\"/content/drive\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PFio7JuXnAmv",
        "outputId": "d8daa31f-f0cb-4cd0-c3e9-ae5d3d0d3f5b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using CUDA\n",
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Loader"
      ],
      "metadata": {
        "id": "I5HS-nESm9xR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ImgDomainAdaptationData(torch.utils.data.Dataset):\n",
        "    def __init__(self, path_A, path_B, id_A, id_B, w, h):\n",
        "\n",
        "        self.transform = transforms.Compose([transforms.Resize([w, h]),\n",
        "                                            transforms.Normalize([0.5], [0.5])])\n",
        "\n",
        "        self.data_A = torch.load(path_A)\n",
        "        self.data_B = torch.load(path_B)\n",
        "\n",
        "        self.img_A = self.transform(self.data_A[0])\n",
        "        self.img_B = self.transform(self.data_B[0])\n",
        "\n",
        "        self.label_A = self.data_A[1]\n",
        "        self.label_B = self.data_B[1]\n",
        "\n",
        "        self.img_A, self.domain_A = self.pre_processing(self.img_A, id_A)\n",
        "        self.img_B, self.domain_B = self.pre_processing(self.img_B, id_B)\n",
        "\n",
        "        self.len = min(self.label_A.shape[0], self.label_B.shape[0])\n",
        "\n",
        "\n",
        "    def pre_processing(self, img, domain):\n",
        "        num_img = img.shape[0]\n",
        "\n",
        "        if len(img.shape) < 4:\n",
        "            img = img.unsqueeze(1).repeat(1, 3, 1, 1)\n",
        "\n",
        "        domain_label = np.zeros(num_img, dtype=int) + domain\n",
        "\n",
        "        return img, domain_label\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.len\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        return (self.img_A[index], self.label_A[index]), (self.img_B[index], self.label_B[index])"
      ],
      "metadata": {
        "id": "tgZf20sCnE1j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Utils"
      ],
      "metadata": {
        "id": "hRGLnDnpnHLE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_imgs(a, b, ab_gen, ba_gen, samples_path, a_name, b_name, epoch=0):\n",
        "    ab_gen.eval()\n",
        "    ba_gen.eval()\n",
        "\n",
        "    b_fake = ab_gen(a)\n",
        "    a_fake = ba_gen(b)\n",
        "\n",
        "    a_imgs = torch.zeros((a.shape[0] * 2, 3, a.shape[2], a.shape[3]))\n",
        "    b_imgs = torch.zeros((b.shape[0] * 2, 3, b.shape[2], b.shape[3]))\n",
        "\n",
        "    even_idx = torch.arange(start=0, end=a.shape[0] * 2, step=2)\n",
        "    odd_idx = torch.arange(start=1, end=a.shape[0] * 2, step=2)\n",
        "\n",
        "    a_imgs[even_idx] = a.cpu()\n",
        "    a_imgs[odd_idx] = b_fake.cpu()\n",
        "\n",
        "    b_imgs[even_idx] = b.cpu()\n",
        "    b_imgs[odd_idx] = a_fake.cpu()\n",
        "\n",
        "    rows = math.ceil((a.shape[0] * 2) ** 0.5)\n",
        "    a_imgs_ = vutils.make_grid(a_imgs, normalize=True, nrow=rows)\n",
        "    b_imgs_ = vutils.make_grid(b_imgs, normalize=True, nrow=rows)\n",
        "\n",
        "    vutils.save_image(a_imgs_, os.path.join(samples_path[0], f'{a_name}_to_{b_name}_ep_{epoch}.png'))\n",
        "    vutils.save_image(b_imgs_, os.path.join(samples_path[1], f'{b_name}_to_{a_name}_ep_{epoch}.png'))"
      ],
      "metadata": {
        "id": "HjuNcugonGxP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CycleGAN Model"
      ],
      "metadata": {
        "id": "FzS2k-4XnJ_j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def conv_block(c_in, c_out, k_size=4, stride=2, pad=1, use_bn=True, transpose=False):\n",
        "    module = []\n",
        "    if transpose:\n",
        "        module.append(nn.ConvTranspose2d(c_in, c_out, k_size, stride, pad, output_padding=pad, bias=not use_bn))\n",
        "    else:\n",
        "        module.append(nn.Conv2d(c_in, c_out, k_size, stride, pad, bias=not use_bn))\n",
        "\n",
        "    if use_bn:\n",
        "        module.append(nn.BatchNorm2d(c_out))\n",
        "    return nn.Sequential(*module)\n",
        "\n",
        "\n",
        "class ResBlock(nn.Module):\n",
        "    def __init__(self, channels):\n",
        "        super(ResBlock, self).__init__()\n",
        "        self.conv1 = conv_block(channels, channels, k_size=3, stride=1, pad=1, use_bn=True)\n",
        "        self.conv2 = conv_block(channels, channels, k_size=3, stride=1, pad=1, use_bn=True)\n",
        "\n",
        "    def __call__(self, x):\n",
        "        x = F.relu(self.conv1(x))\n",
        "        return x + self.conv2(x)\n",
        "\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, channels=3, conv_dim=64):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.conv1 = conv_block(channels, conv_dim, use_bn=False)\n",
        "        self.conv2 = conv_block(conv_dim, conv_dim * 2)\n",
        "        self.conv3 = conv_block(conv_dim * 2, conv_dim * 4)\n",
        "        self.conv4 = conv_block(conv_dim * 4, 1, k_size=3, stride=1, pad=1, use_bn=False)\n",
        "\n",
        "        # Initialization\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d) or isinstance(m, nn.ConvTranspose2d):\n",
        "                nn.init.normal_(m.weight, 0.0, 0.02)\n",
        "            elif isinstance(m, nn.BatchNorm2d):\n",
        "                nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "\n",
        "    def forward(self, x):\n",
        "        alpha = 0.2\n",
        "        x = F.leaky_relu(self.conv1(x), alpha)\n",
        "        x = F.leaky_relu(self.conv2(x), alpha)\n",
        "        x = F.leaky_relu(self.conv3(x), alpha)\n",
        "        x = self.conv4(x)\n",
        "        x = x.reshape([x.shape[0], -1]).mean(1)\n",
        "        return x\n",
        "\n",
        "\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self, in_channels=3, out_channels=3, conv_dim=64):\n",
        "        super(Generator, self).__init__()\n",
        "        self.conv1 = conv_block(in_channels, conv_dim, k_size=5, stride=1, pad=2, use_bn=True)\n",
        "        self.conv2 = conv_block(conv_dim, conv_dim * 2, k_size=3, stride=2, pad=1, use_bn=True)\n",
        "        self.conv3 = conv_block(conv_dim * 2, conv_dim * 4, k_size=3, stride=2, pad=1, use_bn=True)\n",
        "        self.res4 = ResBlock(conv_dim * 4)\n",
        "        self.tconv5 = conv_block(conv_dim * 4, conv_dim * 2, k_size=3, stride=2, pad=1, use_bn=True, transpose=True)\n",
        "        self.tconv6 = conv_block(conv_dim * 2, conv_dim, k_size=3, stride=2, pad=1, use_bn=True, transpose=True)\n",
        "        self.conv7 = conv_block(conv_dim, out_channels, k_size=5, stride=1, pad=2, use_bn=False)\n",
        "\n",
        "        # Initialization\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d) or isinstance(m, nn.ConvTranspose2d):\n",
        "                nn.init.normal_(m.weight, 0.0, 0.02)\n",
        "            elif isinstance(m, nn.BatchNorm2d):\n",
        "                nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = F.relu(self.conv3(x))\n",
        "        x = F.relu(self.res4(x))\n",
        "        x = F.relu(self.tconv5(x))\n",
        "        x = F.relu(self.tconv6(x))\n",
        "        x = torch.tanh(self.conv7(x))\n",
        "        return x"
      ],
      "metadata": {
        "id": "KqWARI_znL9M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training Settings"
      ],
      "metadata": {
        "id": "w0QRg0MbnP4G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "MNIST_train_path = '/content/drive/My Drive/CycleGAN/4-digit dataset/MNIST_train.pt'\n",
        "SYN_train_path = '/content/drive/My Drive/CycleGAN/4-digit dataset/SYN_train.pt'\n",
        "USPS_train_path = '/content/drive/My Drive/CycleGAN/4-digit dataset/USPS_train.pt'\n",
        "\n",
        "ds_path = [MNIST_train_path, SYN_train_path, USPS_train_path]\n",
        "\n",
        "MNIST_domain_id = 0\n",
        "SYN_domain_id = 1\n",
        "USPS_domain_id = 2\n",
        "\n",
        "DS_NAME = [\"MNIST\", \"SYN\", \"USPS\"]\n",
        "\n",
        "\n",
        "EPOCHS = 50  # 50-300\n",
        "N_CRITIC = 5\n",
        "BATCH_SIZE = 128\n",
        "IMGS_TO_DISPLAY = 32\n",
        "\n",
        "IMAGE_SIZE = 32\n",
        "NUM_DOMAINS = 2\n",
        "\n",
        "GRADIENT_PENALTY = 10\n",
        "CONV_DIM = 12\n",
        "\n",
        "model_path = '/content/drive/My Drive/CycleGAN/model'\n",
        "samples_path = model_path = '/content/drive/My Drive/CycleGAN/samples'\n",
        "os.makedirs(model_path, exist_ok=True)\n",
        "os.makedirs(samples_path, exist_ok=True)"
      ],
      "metadata": {
        "id": "ks8ipSydnRuL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training Loop"
      ],
      "metadata": {
        "id": "SxysVVBQn1ws"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class EarlyStopping:\n",
        "    \"\"\"Early stops the training if cycle consistency loss doesn't improve after a given patience.\"\"\"\n",
        "    def __init__(self, patience=10, verbose=False, epsilon=1.001):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            patience (int): How long to wait after last time cycle consistency loss improved.\n",
        "                            Default: 7\n",
        "            verbose (bool): If True, prints a message for each validation loss improvement.\n",
        "                            Default: False\n",
        "            delta (float): Minimum change in the monitored quantity to qualify as an improvement.\n",
        "                           Default: 0\n",
        "        \"\"\"\n",
        "        self.patience = patience\n",
        "        self.verbose = verbose\n",
        "        self.counter = 0\n",
        "        self.best_score = None\n",
        "        self.early_stop = False\n",
        "        self.cycle_loss_min = np.inf  # Changed from np.Inf to np.inf\n",
        "        self.epsilon = epsilon\n",
        "\n",
        "    def __call__(self, cycle_loss, gen, dis):\n",
        "\n",
        "        score = -cycle_loss\n",
        "\n",
        "        if self.best_score is None:\n",
        "            self.best_score = score\n",
        "            self.save_checkpoint(cycle_loss, gen, dis)\n",
        "        elif score < self.best_score / self.epsilon:\n",
        "            self.counter += 1\n",
        "            print(f'\\nCurrent cycle consistency loss {cycle_loss:.6f} > {self.cycle_loss_min:.6f}/{self.epsilon} = {self.cycle_loss_min/self.epsilon:.6f}')\n",
        "            print(f'EarlyStopping counter: {self.counter} out of {self.patience}\\n')\n",
        "            if self.counter >= self.patience:\n",
        "                self.early_stop = True\n",
        "        else:\n",
        "            self.best_score = score\n",
        "            self.save_checkpoint(cycle_loss, gen, dis)\n",
        "            self.counter = 0\n",
        "\n",
        "    def save_checkpoint(self, cycle_loss, gen, dis):\n",
        "        '''Saves model when the cycle consistency loss decrease.'''\n",
        "\n",
        "        gen_ab, gen_ba = gen\n",
        "        dis_a, dis_b = dis\n",
        "\n",
        "        if self.verbose:\n",
        "            print(f'\\ncycle consistency loss decreased ({self.cycle_loss_min:.6f} --> {cycle_loss:.6f}).  Saving model ...\\n')\n",
        "        # Note: Here you should define how you want to save your model. For example:\n",
        "        # Ensure dm_a and dm_b are accessible here (they are global in the provided context)\n",
        "        torch.save(gen_ab.state_dict(), os.path.join(model_path, f'gen_{DS_NAME[dm_a]}_{DS_NAME[dm_b]}.pkl'))\n",
        "        torch.save(gen_ba.state_dict(), os.path.join(model_path, f'gen_{DS_NAME[dm_b]}_{DS_NAME[dm_a]}.pkl'))\n",
        "\n",
        "        torch.save(dis_a.state_dict(), os.path.join(model_path, f'dis_{DS_NAME[dm_a]}.pkl'))\n",
        "        torch.save(dis_b.state_dict(), os.path.join(model_path, f'dis_{DS_NAME[dm_b]}.pkl'))\n",
        "\n",
        "        self.cycle_loss_min = cycle_loss"
      ],
      "metadata": {
        "id": "KNx1u2gIn2pu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from tqdm import tqdm\n",
        "\n",
        "# ab_combinations: each row is [src_domain, tgt_domain]\n",
        "ab_combinations = np.array([[0, 1],\n",
        "                            [0, 2],\n",
        "                            [1, 2]])\n",
        "# Example domain name list, e.g. [\"MNIST\", \"SYN\", \"USPS\"]\n",
        "# DS_NAME = [...]\n",
        "# ds_path = [...]  # training dataset paths for each domain\n",
        "\n",
        "# Hyperparameters & other settings (adjust as needed)\n",
        "CONV_DIM = 64\n",
        "BATCH_SIZE = 64\n",
        "EPOCHS = 50\n",
        "IMAGE_SIZE = 28\n",
        "IMGS_TO_DISPLAY = 8\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "for dm_a, dm_b in ab_combinations:\n",
        "    # 1) Define and initialize generators & discriminators\n",
        "    gen_ab = Generator(in_channels=3, out_channels=3, conv_dim=CONV_DIM).to(device).train()\n",
        "    gen_ba = Generator(in_channels=3, out_channels=3, conv_dim=CONV_DIM).to(device).train()\n",
        "\n",
        "    dis_a = Discriminator(channels=3).to(device).train()\n",
        "    dis_b = Discriminator(channels=3).to(device).train()\n",
        "\n",
        "    # 2) Define optimizers for G & D\n",
        "    g_optim = optim.Adam(\n",
        "        list(gen_ab.parameters()) + list(gen_ba.parameters()),\n",
        "        lr=0.0001,\n",
        "        betas=(0.5, 0.999)\n",
        "    )\n",
        "    d_optim = optim.Adam(\n",
        "        list(dis_a.parameters()) + list(dis_b.parameters()),\n",
        "        lr=0.0001,\n",
        "        betas=(0.5, 0.999)\n",
        "    )\n",
        "\n",
        "    # 3) Data loader for domain A and B\n",
        "    # (ImgDomainAdaptationData should yield (a_real, a_label), (b_real, b_label))\n",
        "    data = ImgDomainAdaptationData(ds_path[dm_a], ds_path[dm_b], dm_a, dm_b, IMAGE_SIZE, IMAGE_SIZE)\n",
        "    ds_loader = torch.utils.data.DataLoader(\n",
        "        data,\n",
        "        batch_size=BATCH_SIZE,\n",
        "        shuffle=True\n",
        "    )\n",
        "    iters_per_epoch = len(ds_loader)\n",
        "\n",
        "    # 4) Prepare fixed samples for visualization\n",
        "    loader_iter = iter(ds_loader)\n",
        "    img_fixed = next(loader_iter)\n",
        "    a_fixed, b_fixed = img_fixed\n",
        "    a_fixed, _ = a_fixed\n",
        "    b_fixed, _ = b_fixed\n",
        "    a_fixed = a_fixed[:IMGS_TO_DISPLAY].to(device)\n",
        "    b_fixed = b_fixed[:IMGS_TO_DISPLAY].to(device)\n",
        "\n",
        "    # 5) Create naming for this experiment (e.g. \"SYN_USPS_conv12_batch64\")\n",
        "    current_setting = f'{DS_NAME[dm_a]}_{DS_NAME[dm_b]}_conv{CONV_DIM}_batch{BATCH_SIZE}'\n",
        "    print(f'Current training setting: {current_setting}')\n",
        "\n",
        "    # 6) Create output directories\n",
        "    model_path_exp = os.path.join(model_path, current_setting)\n",
        "    os.makedirs(model_path_exp, exist_ok=True)\n",
        "\n",
        "    samples_path_exp = os.path.join(samples_path, current_setting)\n",
        "    samples_path_ab = os.path.join(samples_path_exp, f'{DS_NAME[dm_a]}_to_{DS_NAME[dm_b]}')\n",
        "    samples_path_ba = os.path.join(samples_path_exp, f'{DS_NAME[dm_b]}_to_{DS_NAME[dm_a]}')\n",
        "    os.makedirs(samples_path_exp, exist_ok=True)\n",
        "    os.makedirs(samples_path_ab, exist_ok=True)\n",
        "    os.makedirs(samples_path_ba, exist_ok=True)\n",
        "\n",
        "    # 7) EarlyStopping + lists to track training info\n",
        "    early_stopping = EarlyStopping(patience=12, verbose=True)\n",
        "\n",
        "    train_info = []\n",
        "    # We‚Äôll keep track of generator adversarial loss, cycle loss, total gen loss, disc loss\n",
        "    # across epochs\n",
        "    g_adv_loss_per_ep = []\n",
        "    g_cyc_loss_per_ep = []\n",
        "    g_loss_per_ep = []\n",
        "    d_loss_per_ep = []\n",
        "\n",
        "    # 8) CycleGAN Training loop\n",
        "    for epoch in range(EPOCHS):\n",
        "        g_adv_losses = []\n",
        "        g_cyc_losses = []\n",
        "        g_losses = []\n",
        "        d_losses = []\n",
        "\n",
        "        for batch_idx, batch_data in tqdm(enumerate(ds_loader), total=iters_per_epoch, desc=f'Epoch {epoch+1}'):\n",
        "            a_data, b_data = batch_data\n",
        "            a_real, _ = a_data\n",
        "            b_real, _ = b_data\n",
        "            a_real, b_real = a_real.to(device), b_real.to(device)\n",
        "\n",
        "            # -----------------------------\n",
        "            # (A) Discriminator Training\n",
        "            # -----------------------------\n",
        "            b_fake = gen_ab(a_real)\n",
        "            a_fake = gen_ba(b_real)\n",
        "\n",
        "            a_real_out = dis_a(a_real)\n",
        "            a_fake_out = dis_a(a_fake.detach())\n",
        "            d_a_loss = (torch.mean((a_real_out - 1) ** 2) + torch.mean(a_fake_out ** 2)) / 2\n",
        "\n",
        "            b_real_out = dis_b(b_real)\n",
        "            b_fake_out = dis_b(b_fake.detach())\n",
        "            d_b_loss = (torch.mean((b_real_out - 1) ** 2) + torch.mean(b_fake_out ** 2)) / 2\n",
        "\n",
        "            d_optim.zero_grad()\n",
        "            d_loss = d_a_loss + d_b_loss\n",
        "            d_loss.backward()\n",
        "            d_optim.step()\n",
        "\n",
        "            # -----------------------------\n",
        "            # (B) Generator Training\n",
        "            # -----------------------------\n",
        "            a_fake_out = dis_a(a_fake)\n",
        "            b_fake_out = dis_b(b_fake)\n",
        "\n",
        "            # Adversarial losses for G\n",
        "            g_a_adv_loss = torch.mean((a_fake_out - 1) ** 2)\n",
        "            g_b_adv_loss = torch.mean((b_fake_out - 1) ** 2)\n",
        "            g_adv_loss = g_a_adv_loss + g_b_adv_loss\n",
        "\n",
        "            # Cycle consistency\n",
        "            a_recon = gen_ba(b_fake)\n",
        "            b_recon = gen_ab(a_fake)\n",
        "            g_a_cyc_loss = (a_real - a_recon).abs().mean()\n",
        "            g_b_cyc_loss = (b_real - b_recon).abs().mean()\n",
        "            g_cyc_loss = g_a_cyc_loss + g_b_cyc_loss\n",
        "\n",
        "            g_optim.zero_grad()\n",
        "            g_loss = g_adv_loss + 10.0 * g_cyc_loss\n",
        "            g_loss.backward()\n",
        "            g_optim.step()\n",
        "\n",
        "            # Collect losses\n",
        "            g_adv_losses.append(g_adv_loss.item())\n",
        "            g_cyc_losses.append(g_cyc_loss.item())\n",
        "            g_losses.append(g_loss.item())\n",
        "            d_losses.append(d_loss.item())\n",
        "\n",
        "        # -----------------------------\n",
        "        # End of epoch: Logging & Visualization\n",
        "        # -----------------------------\n",
        "        generate_imgs(\n",
        "            a_fixed, b_fixed,\n",
        "            gen_ab, gen_ba,\n",
        "            (samples_path_ab, samples_path_ba),\n",
        "            DS_NAME[dm_a], DS_NAME[dm_b],\n",
        "            epoch+1\n",
        "        )\n",
        "\n",
        "        avg_g_adv_loss = np.mean(g_adv_losses)\n",
        "        avg_g_cyc_loss = np.mean(g_cyc_losses)\n",
        "        avg_g_loss = np.mean(g_losses)\n",
        "        avg_d_loss = np.mean(d_losses)\n",
        "\n",
        "        train_info.append([avg_g_adv_loss, avg_g_cyc_loss, avg_g_loss, avg_d_loss])\n",
        "\n",
        "        print(f\"\\nEpoch [{epoch+1}/{EPOCHS}] - {current_setting}\")\n",
        "        print(f\"Generator:\\n  adv_loss: {avg_g_adv_loss:.6f}, cyc_loss: {avg_g_cyc_loss:.6f}, total: {avg_g_loss:.6f}\")\n",
        "        print(\"Discriminator:\")\n",
        "        print(f\"  total_loss: {avg_d_loss:.6f}\")\n",
        "        print(\"==========================================\")\n",
        "\n",
        "        # Early stopping on cycle loss (or whichever metric you prefer)\n",
        "        early_stopping(avg_g_cyc_loss, (gen_ab, gen_ba), (dis_a, dis_b))\n",
        "        if early_stopping.early_stop:\n",
        "            print(f\"Early stopping triggered at epoch {epoch+1}.\")\n",
        "            break\n",
        "\n",
        "    # Generate final images with epoch=-1 or similar naming\n",
        "    generate_imgs(\n",
        "        a_fixed, b_fixed,\n",
        "        gen_ab, gen_ba,\n",
        "        (samples_path_ab, samples_path_ba),\n",
        "        DS_NAME[dm_a], DS_NAME[dm_b],\n",
        "        -1\n",
        "    )\n",
        "\n",
        "    # Save training info to CSV\n",
        "    df = pd.DataFrame(train_info, columns=['Gen Adv Loss', 'Gen Cyc Loss', 'Gen Total Loss', 'Dis Total Loss'])\n",
        "    train_info_path = os.path.join('.', 'train_info', current_setting)\n",
        "    os.makedirs(train_info_path, exist_ok=True)\n",
        "    df_path = os.path.join(train_info_path, 'train_info.csv')\n",
        "    df.to_csv(df_path, index=True)\n",
        "    print(f'Saved training info to {df_path}')\n",
        "\n",
        "print(\"All training complete!\")"
      ],
      "metadata": {
        "id": "m55iduaunJgt"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
